# Alignment

This repository contains experiments that aim to leverage kernel methods in order to shed light on the generalization properties of neural networks. In particular, we investigate the evolution of the empirical neural tangent kernel of shallow networks throughout the training process, and we quantify how the NTK becomes more "aligned" with the training data as training progresses. 


# References
- [When do Neural Networks Outperform Kernel Methods?](https://arxiv.org/pdf/2006.13409.pdf)
- [Geometric compression of invariant manifolds in neural nets](https://arxiv.org/pdf/2007.11471.pdf)




